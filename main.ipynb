{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling, model utilization, and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf  # For collecting financial data\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from scipy.optimize import minimize \n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "# Import the custom Model class\n",
    "from Model import Model\n",
    "\n",
    "# Set the random seed for reproducibility across numpy and tensorflow\n",
    "np.random.seed(123)\n",
    "\n",
    "# Optional: Configure plotting style for a consistent look\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Define the tickers and date range with consideration of trading days\n",
    "TICKERS = ['VTI','AGG','DBC','VIXY']  # Example tickers for the portfolio\n",
    "START_DATE = '2018-01-01'\n",
    "END_DATE = '2023-01-01'\n",
    "\n",
    "# Approximate number of trading days per year (useful for annualizing returns)\n",
    "TRADING_DAYS_PER_YEAR = 252\n",
    "\n",
    "# Confirm setup\n",
    "print(\"Setup complete: libraries imported, random seed set, and tickers defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection Step\n",
    "# Objective: Fetch historical adjusted close prices for defined tickers and date range\n",
    "\n",
    "# Download data using yfinance for the specified tickers and date range\n",
    "def get_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Retrieves historical adjusted close prices for the given tickers and date range.\n",
    "    \n",
    "    Parameters:\n",
    "    - tickers: List of stock ticker symbols\n",
    "    - start_date: Start date for historical data\n",
    "    - end_date: End date for historical data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame of adjusted close prices, with each column representing a ticker\n",
    "    \"\"\"\n",
    "    # Fetch data from yfinance\n",
    "    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "    \n",
    "    # Drop rows with missing values, if any, to ensure data continuity\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Fetch the data and display a quick preview\n",
    "data = get_data(TICKERS, START_DATE, END_DATE)\n",
    "print(\"Data fetched successfully. Sample data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Confirm data spans the expected range and has the expected number of columns\n",
    "print(f\"Data covers {len(data)} trading days with {len(data.columns)} assets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Step\n",
    "# Objective: Prepare data by calculating daily returns and normalizing for model input\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Prepares data for the LSTM model by calculating returns and normalizing prices.\n",
    "\n",
    "    Parameters:\n",
    "    - data: DataFrame of historical adjusted close prices for assets\n",
    "\n",
    "    Returns:\n",
    "    - normalized_data: DataFrame with prices normalized to start at 1 for each asset\n",
    "    - returns: DataFrame with daily returns for each asset\n",
    "    \"\"\"\n",
    "    # Calculate daily returns as percentage changes\n",
    "    returns = data.pct_change().dropna()\n",
    "    \n",
    "    # Normalize prices so each series starts at 1\n",
    "    normalized_data = data / data.iloc[0]\n",
    "    \n",
    "    return normalized_data, returns\n",
    "\n",
    "# Run preprocessing and display sample data\n",
    "normalized_data, returns = preprocess_data(data)\n",
    "print(\"Data preprocessing complete. Sample normalized data:\")\n",
    "print(normalized_data.head())\n",
    "print(\"\\nSample daily returns:\")\n",
    "print(returns.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    def __init__(self, initial_cash: float, assets: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initializes the Portfolio object.\n",
    "\n",
    "        Parameters:\n",
    "        - initial_cash: The starting value of the portfolio in cash.\n",
    "        - assets: DataFrame of asset prices (historical data).\n",
    "        \"\"\"\n",
    "        self.initial_cash = initial_cash\n",
    "        self.current_value = initial_cash\n",
    "        self.assets = assets  # Historical price data for the assets\n",
    "        self.weights = np.zeros(len(assets.columns))  # Initialize weights as zero\n",
    "        self.portfolio_history = []  # To track portfolio value over time\n",
    "        self.rebalancing_dates = []  # To store rebalancing dates\n",
    "\n",
    "    def rebalance(self, new_weights: np.array):\n",
    "        \"\"\"\n",
    "        Rebalances the portfolio according to new weights.\n",
    "\n",
    "        Parameters:\n",
    "        - new_weights: Numpy array of asset allocations.\n",
    "        \"\"\"\n",
    "        if len(new_weights) != len(self.assets.columns):\n",
    "            raise ValueError(\"Number of weights must match the number of assets.\")\n",
    "        self.weights = new_weights\n",
    "\n",
    "    def calculate_initial_shares(self, initial_cash, initial_prices):\n",
    "        \"\"\"\n",
    "        Calculates the number of shares for each asset at the start of the testing period based on\n",
    "        initial cash and allocation weights.\n",
    "\n",
    "        Parameters:\n",
    "        - initial_cash: The starting cash value of the portfolio.\n",
    "\n",
    "        Returns:\n",
    "        - shares: Dictionary with tickers as keys and the initial number of shares as values.\n",
    "        \"\"\"\n",
    "        # Calculate the dollar amount allocated to each asset\n",
    "        dollar_allocation = initial_cash * self.weights\n",
    "\n",
    "        # Calculate the number of shares for each asset\n",
    "        shares = (dollar_allocation // initial_prices).astype(int)  # Floor division to get whole shares\n",
    "\n",
    "        # Return as a dictionary for easy readability\n",
    "        return dict(zip(self.assets.columns, shares))\n",
    "    \n",
    "    def calculate_daily_returns(self):\n",
    "        \"\"\"\n",
    "        Applies the current weights to asset returns and updates portfolio value over time.\n",
    "        \"\"\"\n",
    "        # Calculate daily returns for each asset\n",
    "        daily_returns = self.assets.pct_change().dropna()\n",
    "        \n",
    "        # Calculate portfolio returns by applying weights\n",
    "        portfolio_returns = np.dot(daily_returns, self.weights)\n",
    "\n",
    "        # Track the portfolio's value over time by compounding the returns\n",
    "        for daily_ret in portfolio_returns:\n",
    "            self.current_value *= (1 + daily_ret)\n",
    "            self.portfolio_history.append(self.current_value)\n",
    "\n",
    "    def track_portfolio_performance(self):\n",
    "        \"\"\"\n",
    "        Tracks and prints the portfolio performance over time.\n",
    "        \"\"\"\n",
    "        for date, value in zip(self.assets.index[1:], self.portfolio_history):\n",
    "            print(f\"Date: {date}, Portfolio Value: {value}\")\n",
    "\n",
    "    def step(self, action):\n",
    "        normalized_action = np.array(action) / np.sum(action)\n",
    "        \n",
    "        self.rebalance(normalized_action)\n",
    "        portfolio_returns = self.calculate_daily_returns()\n",
    "\n",
    "        self.current_value *= (1 + portfolio_returns[-1])\n",
    "        self.portfolio_history.append(self.current_value)\n",
    "\n",
    "        daily_returns = np.array(self.portfolio_history)\n",
    "        returns = daily_returns[1:] / daily_returns[:-1] - 1\n",
    "        mean_returns = np.mean(returns)\n",
    "        std_returns = np.std(returns)\n",
    "        reward = mean_returns / std_returns if std_returns != 0 else 0\n",
    "\n",
    "        normalized_prices = self.assets / self.assets.iloc[0]\n",
    "        next_state = normalized_prices.values[-1]\n",
    "\n",
    "        done = self.current_value <= self.initial_cash * 0.75\n",
    "\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def get_portfolio_value(self):\n",
    "        \"\"\"\n",
    "        Returns the current value of the portfolio.\n",
    "        \"\"\"\n",
    "        return self.current_value\n",
    "    \n",
    "    def plot_portfolio_value(self):\n",
    "        \"\"\"\n",
    "        Plots the portfolio value over time.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.assets.index[1:], self.portfolio_history, label=\"Portfolio Value\")\n",
    "        plt.title(\"Portfolio Value Over Time\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Portfolio Value\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_rebalance_portfolio(portfolio: Portfolio, frequency: int, model: Model):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model and rebalances the portfolio at the end of each specified interval.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio: An instance of the Portfolio class.\n",
    "    - frequency: The frequency of rebalancing in days.\n",
    "    - model: An instance of the Model class for training.\n",
    "    \"\"\"\n",
    "    num_days = len(portfolio.assets)\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < num_days:\n",
    "        # Determine the end index for the current training period\n",
    "        end_index = min(start_index + frequency, num_days)\n",
    "\n",
    "        # Slice the data for the training period\n",
    "        train_data = portfolio.assets.iloc[start_index:end_index]\n",
    "\n",
    "        # Preprocess the training data\n",
    "        normalized_data, _ = preprocess_data(train_data)\n",
    "\n",
    "        # Get allocations from the model\n",
    "        allocations = model.get_allocations(normalized_data)\n",
    "\n",
    "        # Rebalance the portfolio with the optimized weights\n",
    "        portfolio.rebalance(allocations)\n",
    "\n",
    "        # Store the rebalancing date\n",
    "        portfolio.rebalancing_dates.append(train_data.index[-1])\n",
    "\n",
    "        # Move to the next period\n",
    "        start_index += frequency\n",
    "    return allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(portfolio_values):\n",
    "    \"\"\"\n",
    "    Calculates performance metrics for the portfolio.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_values: List of daily portfolio values over the testing period.\n",
    "\n",
    "    Returns:\n",
    "    - metrics: Dictionary containing Sharpe Ratio, Sortino Ratio, and Max Drawdown.\n",
    "    \"\"\"\n",
    "    # Convert portfolio values to daily returns\n",
    "    portfolio_returns = np.diff(portfolio_values) / portfolio_values[:-1]\n",
    "    \n",
    "    # Calculate Sharpe Ratio\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    std_dev = np.std(portfolio_returns)\n",
    "    sharpe_ratio = mean_return / std_dev * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "    \n",
    "    # Calculate Sortino Ratio\n",
    "    downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "    downside_std_dev = np.std(downside_returns)\n",
    "    sortino_ratio = mean_return / downside_std_dev * np.sqrt(TRADING_DAYS_PER_YEAR)\n",
    "    \n",
    "    # Calculate Maximum Drawdown\n",
    "    cumulative_returns = np.maximum.accumulate(portfolio_values) - portfolio_values\n",
    "    max_drawdown = np.max(cumulative_returns / np.maximum.accumulate(portfolio_values))\n",
    "    \n",
    "    return {\n",
    "        \"Sharpe Ratio\": sharpe_ratio,\n",
    "        \"Sortino Ratio\": sortino_ratio,\n",
    "        \"Max Drawdown\": max_drawdown\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_weighted_strategy(returns):\n",
    "    \"\"\"\n",
    "    Creates an equal-weighted portfolio.\n",
    "\n",
    "    Parameters:\n",
    "    - returns: DataFrame of daily returns for each asset.\n",
    "\n",
    "    Returns:\n",
    "    - equal_weights: Numpy array of equal weights for each asset.\n",
    "    \"\"\"\n",
    "    num_assets = returns.shape[1]\n",
    "    equal_weights = np.ones(num_assets) / num_assets\n",
    "    return equal_weights\n",
    "\n",
    "def mean_variance_optimized_strategy(returns):\n",
    "    \"\"\"\n",
    "    Creates a mean-variance optimized portfolio by maximizing the Sharpe Ratio.\n",
    "\n",
    "    Parameters:\n",
    "    - returns: DataFrame of daily returns for each asset.\n",
    "\n",
    "    Returns:\n",
    "    - optimized_weights: Numpy array of optimized weights for each asset.\n",
    "    \"\"\"\n",
    "    mean_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    "    \n",
    "    def neg_sharpe(weights):\n",
    "        portfolio_return = np.dot(weights, mean_returns)\n",
    "        portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return -portfolio_return / portfolio_std\n",
    "\n",
    "    # Constraints: Weights must sum to 1, and each weight must be between 0 and 1\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bounds = tuple((0, 1) for _ in range(returns.shape[1]))\n",
    "\n",
    "    result = minimize(neg_sharpe, np.ones(returns.shape[1]) / returns.shape[1], bounds=bounds, constraints=constraints)\n",
    "    optimized_weights = result.x\n",
    "    \n",
    "    return optimized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation for Training and Testing\n",
    "train_data = get_data(TICKERS, START_DATE, END_DATE)\n",
    "normalized_train_data, _ = preprocess_data(train_data)\n",
    "\n",
    "testing_data = get_data(TICKERS, '2023-01-01', '2024-01-01')\n",
    "normalized_testing_data, testing_returns = preprocess_data(testing_data)\n",
    "\n",
    "# Step 2: Train and Rebalance Portfolio in Training Phase (rebalancing every two years)\n",
    "training_portfolio = Portfolio(100000, normalized_train_data)\n",
    "model = Model()\n",
    "initial_prices = testing_data.loc[testing_data.index[0]]  # First row of the actual price data\n",
    "# Rebalance every 2 years (252 trading days * 2)\n",
    "final_allocations = train_and_rebalance_portfolio(training_portfolio, frequency=30, model=model)\n",
    "\n",
    "# Step 3: Initialize Testing Portfolio with Final LSTM Weights\n",
    "testing_portfolio = Portfolio(100000, normalized_testing_data)\n",
    "testing_portfolio.rebalance(final_allocations)\n",
    "LSTM_shares = testing_portfolio.calculate_initial_shares(100000,initial_prices)  # Calculate initial shares based on final allocations\n",
    "testing_portfolio.calculate_daily_returns()     # Track performance in testing period\n",
    "testing_portfolio.plot_portfolio_value()        # Visualize portfolio value over time\n",
    "# Step 4: Calculate Performance Metrics for LSTM Portfolio\n",
    "metrics = calculate_metrics(testing_portfolio.portfolio_history)\n",
    "\n",
    "# Step 5: Baseline Strategies Setup and Evaluation\n",
    "# Equal-Weighted and Mean-Variance Optimized Portfolios\n",
    "equal_weights = equal_weighted_strategy(testing_returns)\n",
    "mv_optimized_weights = mean_variance_optimized_strategy(testing_returns)\n",
    "\n",
    "equal_weight_portfolio = Portfolio(100000, normalized_testing_data)\n",
    "mv_optimized_portfolio = Portfolio(100000, normalized_testing_data)\n",
    "\n",
    "equal_weight_portfolio.rebalance(equal_weights)\n",
    "mv_optimized_portfolio.rebalance(mv_optimized_weights)\n",
    "\n",
    "equal_weight_portfolio.calculate_daily_returns()\n",
    "mv_optimized_portfolio.calculate_daily_returns()\n",
    "ew_shares = equal_weight_portfolio.calculate_initial_shares(100000,initial_prices)\n",
    "mv_shares = mv_optimized_portfolio.calculate_initial_shares(100000,initial_prices)\n",
    "equal_weight_portfolio.plot_portfolio_value()\n",
    "mv_optimized_portfolio.plot_portfolio_value()\n",
    "# Step 6: Calculate Performance Metrics for Baseline Portfolios\n",
    "equal_weight_metrics = calculate_metrics(equal_weight_portfolio.portfolio_history)\n",
    "mv_optimized_metrics = calculate_metrics(mv_optimized_portfolio.portfolio_history)\n",
    "\n",
    "print(\"LSTM Portfolio Metrics:\")\n",
    "print(f\"Weights:{final_allocations}, Shares:{LSTM_shares}\")\n",
    "print(metrics)\n",
    "print(\"\\nEqual-Weighted Portfolio Metrics:\")\n",
    "print(f\"Weights:{equal_weights}, Shares:{ew_shares}\")\n",
    "print(equal_weight_metrics)\n",
    "\n",
    "print(\"\\nMean-Variance Optimized Portfolio Metrics:\")\n",
    "print(f\"Weights:{mv_optimized_weights}, Shares:{mv_shares}\")\n",
    "print(mv_optimized_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparison of performance with different training frequencies\n",
    "model2 = Model()\n",
    "training_portfolio = Portfolio(100000, normalized_train_data)\n",
    "initial_prices = testing_data.loc[testing_data.index[0]]  # First row of the actual price data\n",
    "# Rebalance every 2 years (252 trading days * 2)\n",
    "final_allocations = train_and_rebalance_portfolio(training_portfolio, frequency=15, model=model2)\n",
    "\n",
    "# Step 3: Initialize Testing Portfolio with Final LSTM Weights\n",
    "testing_portfolio = Portfolio(100000, normalized_testing_data)\n",
    "testing_portfolio.rebalance(final_allocations)\n",
    "LSTM_shares = testing_portfolio.calculate_initial_shares(100000,initial_prices)  # Calculate initial shares based on final allocations\n",
    "testing_portfolio.calculate_daily_returns()     # Track performance in testing period\n",
    "testing_portfolio.plot_portfolio_value()        # Visualize portfolio value over time\n",
    "# Step 4: Calculate Performance Metrics for LSTM Portfolio\n",
    "metrics = calculate_metrics(testing_portfolio.portfolio_history)\n",
    "print(\"LSTM Portfolio Metrics:\")\n",
    "print(f\"Weights:{final_allocations}, Shares:{LSTM_shares}\")\n",
    "print(metrics)\n",
    "\n",
    "model3 = Model()\n",
    "training_portfolio = Portfolio(100000, normalized_train_data)\n",
    "initial_prices = testing_data.loc[testing_data.index[0]]  # First row of the actual price data\n",
    "# Rebalance every 2 years (252 trading days * 2)\n",
    "final_allocations = train_and_rebalance_portfolio(training_portfolio, frequency=20, model=model3)\n",
    "\n",
    "# Step 3: Initialize Testing Portfolio with Final LSTM Weights\n",
    "testing_portfolio = Portfolio(100000, normalized_testing_data)\n",
    "testing_portfolio.rebalance(final_allocations)\n",
    "LSTM_shares = testing_portfolio.calculate_initial_shares(100000,initial_prices)  # Calculate initial shares based on final allocations\n",
    "testing_portfolio.calculate_daily_returns()     # Track performance in testing period\n",
    "testing_portfolio.plot_portfolio_value()        # Visualize portfolio value over time\n",
    "# Step 4: Calculate Performance Metrics for LSTM Portfolio\n",
    "metrics = calculate_metrics(testing_portfolio.portfolio_history)\n",
    "print(\"LSTM Portfolio Metrics:\")\n",
    "print(f\"Weights:{final_allocations}, Shares:{LSTM_shares}\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing clearly suggests a higher rebalancing frequency leads to better results, but with a greater risk of overfitting. I think opting for 15 days between rebalances would increase efficiency and reduce overfitting without sacrificing too much performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioRLAgent:\n",
    "    def __init__(self, state_size, action_size, portfolio):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.portfolio = portfolio\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0 \n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.rand(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return act_values[0]\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(episodes, portfolio):\n",
    "    agent = PortfolioRLAgent(state_size=len(portfolio.assets.columns) * 2, action_size=len(portfolio.assets.columns), portfolio=portfolio)\n",
    "    for e in range(episodes):\n",
    "        state = np.reshape(portfolio.assets.values.flatten(), [1, len(portfolio.assets.columns) * 2])\n",
    "        for time in range(2000):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = portfolio.step(action)\n",
    "            reward = reward if not done else -10\n",
    "            next_state = np.reshape(next_state, [1, len(portfolio.assets.columns) * 2])\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}\".format(e, episodes, time))\n",
    "                break\n",
    "        agent.replay(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual(num_assets):\n",
    "    weights = np.random.rand(num_assets)\n",
    "    return weights / np.sum(weights)\n",
    "\n",
    "def mutate(individual, mutation_rate=0.01):\n",
    "    if random.random() < mutation_rate:\n",
    "        mutation_idx = random.randint(0, len(individual) - 1)\n",
    "        individual[mutation_idx] += np.random.normal(0, 0.1)\n",
    "        individual = np.maximum(individual, 0) \n",
    "        individual /= np.sum(individual) \n",
    "    return individual\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    child1, child2 = np.array(parent1), np.array(parent2)\n",
    "    idx = random.randint(1, len(parent1) - 1)\n",
    "    child1[:idx], child2[:idx] = parent2[:idx], parent1[:idx]\n",
    "    child1 /= child1.sum() \n",
    "    child2 /= child2.sum()\n",
    "    return child1, child2\n",
    "\n",
    "def select(population, fitnesses, num_parents):\n",
    "    selected_indices = np.random.choice(len(population), size=num_parents, replace=False, p=fitnesses/fitnesses.sum())\n",
    "    return [population[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(individual, portfolio):\n",
    "    portfolio.rebalance(individual)\n",
    "    portfolio.calculate_daily_returns()\n",
    "    return portfolio.calculate_sharpe_ratio()\n",
    "\n",
    "def run_genetic_algorithm(portfolio, num_assets, num_generations=50, population_size=100, num_parents=50):\n",
    "    population = [create_individual(num_assets) for _ in range(population_size)]\n",
    "    \n",
    "    for generation in range(num_generations):\n",
    "        fitnesses = np.array([calculate_fitness(ind, portfolio) for ind in population])\n",
    "        \n",
    "        parents = select(population, fitnesses, num_parents)\n",
    "        \n",
    "        children = []\n",
    "        while len(children) < population_size:\n",
    "            parent1, parent2 = random.sample(parents, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            child1 = mutate(child1)\n",
    "            child2 = mutate(child2)\n",
    "            children.append(child1)\n",
    "            children.append(child2)\n",
    "        \n",
    "        population = children[:population_size]\n",
    "        \n",
    "        print(f\"Generation {generation} best fitness: {max(fitnesses)}\")\n",
    "    \n",
    "    best_idx = np.argmax(fitnesses)\n",
    "    return population[best_idx]\n",
    "\n",
    "historical_data = get_data(TICKERS, START_DATE, END_DATE)\n",
    "portfolio = Portfolio(100000, historical_data)\n",
    "optimal_weights = run_genetic_algorithm(portfolio, num_assets=len(TICKERS), num_generations=100, population_size=50)\n",
    "print(\"Optimal weights found by GA:\", optimal_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "752aa10ea37be203d6cab1a1d24cb7c4238382709193ae02f57ae36f652cff76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
